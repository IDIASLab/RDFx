{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "203e47bb-fd0c-4070-b22b-8edda8db90f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# this code is run in Databricks \n",
    "# pip install sparkkgml library\n",
    "!pip install sparkkgml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "334b1f22-ca16-466e-b6bf-5296222fd2bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import necessary modules from sparkkgml \n",
    "import time\n",
    "from sparkkgml.data_acquisition import DataAcquisition\n",
    "from sparkkgml.feature_engineering import FeatureEngineering\n",
    "from sparkkgml.vectorization import Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "504e1d2e-d3bd-49bf-bb90-38b0d174b884",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# prepare endpoint and 3 type of queries\n",
    "\n",
    "endpoint = \"https://sparkkgml.arcc.albany.edu/lmdb\"\n",
    "\n",
    "\n",
    "small_query =\"\"\" SELECT\n",
    "                ?movie \n",
    "                WHERE {\n",
    "                ?movie <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://data.linkedmdb.org/movie/film> .\n",
    "                }\n",
    "      \"\"\"\n",
    "\n",
    "mid_query =\"\"\" SELECT\n",
    "                ?movie ?movie__down_title\n",
    "                WHERE {\n",
    "                ?movie <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://data.linkedmdb.org/movie/film> .\n",
    "                OPTIONAL {\n",
    "                ?movie <http://purl.org/dc/terms/title> ?movie__down_title .\n",
    "                 }\n",
    "                }\n",
    "      \"\"\"\n",
    "\n",
    "big_query =\"\"\"SELECT\n",
    "        ?movie\n",
    "        ?movie__down_genre__down_film_genre_name\n",
    "        ?movie__down_date ?movie__down_title\n",
    "        ?movie__down_runtime ?movie__down_actor__down_actor_name\n",
    "        WHERE {\n",
    "        ?movie <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://data.linkedmdb.org/movie/film> .\n",
    "        OPTIONAL { ?movie <http://purl.org/dc/terms/date> ?movie__down_date . }\n",
    "        OPTIONAL { ?movie <http://purl.org/dc/terms/title> ?movie__down_title . }\n",
    "        OPTIONAL { ?movie <http://data.linkedmdb.org/movie/runtime> ?movie__down_runtime . }\n",
    "        OPTIONAL { ?movie <http://data.linkedmdb.org/movie/actor> ?movie__down_actor . ?movie__down_actor  <http://data.linkedmdb.org/movie/actor_name> ?movie__down_actor__down_actor_name . }\n",
    "        OPTIONAL { ?movie <http://data.linkedmdb.org/movie/genre> ?movie__down_genre . ?movie__down_genre <http://data.linkedmdb.org/movie/film_genre_name> ?movie__down_genre__down_film_genre_name . }\n",
    "         }\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb67bf9-0abc-4b2f-b9b5-02e1fa6e1915",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Small Query\n",
    "# run the code in a loop and append runtimes for every run \n",
    "data_acq_times=[]\n",
    "\n",
    "for i in range(10):\n",
    "    total_time_start = time.time()\n",
    "    # create an instance of DataAcquisition\n",
    "    # set parameters for null values\n",
    "    dataAcquisitionObject=DataAcquisition(spark)\n",
    "    dataAcquisitionObject.set_amputationMethod('nullReplacement')\n",
    "    dataAcquisitionObject.set_nullReplacementMethod('customValue')\n",
    "    dataAcquisitionObject.set_customValueVariable(-1)\n",
    "    dataAcquisitionObject.set_customStringValueVariable(' ')\n",
    "\n",
    "    # retrieve data as a Spark DataFrame\n",
    "    start_time1 = time.time()\n",
    "    df = dataAcquisitionObject.getDataFrame(endpoint=endpoint, query=small_query)\n",
    "    end_time1 = time.time()\n",
    "    data_acq_times.append(round(end_time1 - start_time1, 2))\n",
    "\n",
    "   \n",
    "print('data_acq_times:',data_acq_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "493b0e4b-f3f4-4358-a58a-c9834330c360",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mid Query\n",
    "# run the code in a loop and append runtimes for every run \n",
    "data_acq_times=[]\n",
    "feature_eng_times=[]\n",
    "vectorization_times=[]\n",
    "total_times=[]\n",
    "\n",
    "for i in range(10):\n",
    "    total_time_start = time.time()\n",
    "    # create an instance of DataAcquisition\n",
    "    # set parameters for null values\n",
    "    dataAcquisitionObject=DataAcquisition(spark)\n",
    "    dataAcquisitionObject.set_amputationMethod('nullReplacement')\n",
    "    dataAcquisitionObject.set_nullReplacementMethod('customValue')\n",
    "    dataAcquisitionObject.set_customValueVariable(-1)\n",
    "    dataAcquisitionObject.set_customStringValueVariable(' ')\n",
    "\n",
    "    # retrieve data as a Spark DataFrame\n",
    "    start_time1 = time.time()\n",
    "    df = dataAcquisitionObject.getDataFrame(endpoint=endpoint, query=mid_query)\n",
    "    end_time1 = time.time()\n",
    "    data_acq_times.append(round(end_time1 - start_time1, 2))\n",
    "\n",
    "    # create an instance of FeatureEngineering\n",
    "    # call getFeatures function and get features for every column\n",
    "    featureEngineeringObject=FeatureEngineering()\n",
    "    start_time1 = time.time()\n",
    "    df2,features=featureEngineeringObject.getFeatures(df)\n",
    "    end_time1 = time.time()\n",
    "    feature_eng_times.append(round(end_time1 - start_time1, 2))\n",
    "\n",
    "    # create an instance of Vectorization module\n",
    "    # call vectorize function and digitaze all the features\n",
    "    vectorizationObject=Vectorization()\n",
    "    start_time1 = time.time()\n",
    "    digitized_df=vectorizationObject.vectorize(df2,features)\n",
    "    end_time1 = time.time()\n",
    "    vectorization_times.append(round(end_time1 - start_time1, 2))\n",
    "\n",
    "    total_time_end = time.time()\n",
    "    total_times.append(round(total_time_end - total_time_start, 2))\n",
    "\n",
    "print('data_acq_times:',data_acq_times)\n",
    "print('feature_eng_times:',feature_eng_times)\n",
    "print('vectorization_times:',vectorization_times)\n",
    "print('total_times:',total_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06ab252c-c2de-43c0-98d9-36e8e7ee3b36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Big Query\n",
    "# run the code in a loop and append runtimes for every run \n",
    "data_acq_times=[]\n",
    "feature_eng_times=[]\n",
    "vectorization_times=[]\n",
    "total_times=[]\n",
    "\n",
    "for i in range(10):\n",
    "    total_time_start = time.time()\n",
    "    # create an instance of DataAcquisition\n",
    "    # set parameters for null values\n",
    "    dataAcquisitionObject=DataAcquisition(spark)\n",
    "    dataAcquisitionObject.set_amputationMethod('nullReplacement')\n",
    "    dataAcquisitionObject.set_nullReplacementMethod('customValue')\n",
    "    dataAcquisitionObject.set_customValueVariable(-1)\n",
    "    dataAcquisitionObject.set_customStringValueVariable(' ')\n",
    "\n",
    "    # retrieve the data as a Spark DataFrame\n",
    "    start_time1 = time.time()\n",
    "    df = dataAcquisitionObject.getDataFrame(endpoint=endpoint, query=big_query)\n",
    "    end_time1 = time.time()\n",
    "    data_acq_times.append(round(end_time1 - start_time1, 2))\n",
    "\n",
    "    # create an instance of FeatureEngineering\n",
    "    # call getFeatures function and get features for every column\n",
    "    featureEngineeringObject=FeatureEngineering()\n",
    "    start_time1 = time.time()\n",
    "    df2,features=featureEngineeringObject.getFeatures(df)\n",
    "    end_time1 = time.time()\n",
    "    feature_eng_times.append(round(end_time1 - start_time1, 2))\n",
    "\n",
    "    # create an instance of Vectorization module\n",
    "    # call vectorize function and digitaze all the features\n",
    "    vectorizationObject=Vectorization()\n",
    "    start_time1 = time.time()\n",
    "    digitized_df=vectorizationObject.vectorize(df2,features)\n",
    "    end_time1 = time.time()\n",
    "    vectorization_times.append(round(end_time1 - start_time1, 2))\n",
    "\n",
    "    total_time_end = time.time()\n",
    "    total_times.append(round(total_time_end - total_time_start, 2))\n",
    "\n",
    "print('data_acq_times:',data_acq_times)\n",
    "print('feature_eng_times:',feature_eng_times)\n",
    "print('vectorization_times:',vectorization_times)\n",
    "print('total_times:',total_times)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "sparkkgml-query-complexity-2",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
