{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0daf6ce-1e11-476b-a45a-06a50ad9feee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import necessary modules from sparkkgml and libraries\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from sparkkgml.data_acquisition import DataAcquisition\n",
    "from sparkkgml.feature_engineering import FeatureEngineering\n",
    "from sparkkgml.vectorization import Vectorization\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import size,length,concat_ws\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdde0989-7d4f-4290-acc9-dec9b308a0a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# prepare endpoint and query\n",
    "endpoint = \"https://sparkkgml.arcc.albany.edu/lmdb\"\n",
    "query =\"\"\"SELECT\n",
    "        ?movie\n",
    "        ?movie_title\n",
    "        ?genre\n",
    "        ?director\n",
    "        ?actor\n",
    "        (<http://www.w3.org/2001/XMLSchema#int>(?movie__down_runtime) as ?runtime)\n",
    "        WHERE { \n",
    "        ?movie <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://data.linkedmdb.org/movie/film> . \n",
    "        ?movie <http://data.linkedmdb.org/movie/genre> ?movie__down_genre . ?movie__down_genre <http://data.linkedmdb.org/movie/film_genre_name> ?genre .\n",
    "       \n",
    "        \n",
    "        OPTIONAL { ?movie <http://purl.org/dc/terms/title> ?movie_title . } \n",
    "        OPTIONAL { ?movie <http://data.linkedmdb.org/movie/runtime> ?movie__down_runtime . } \n",
    "        OPTIONAL { ?movie <http://data.linkedmdb.org/movie/actor> ?movie__down_actor . ?movie__down_actor <http://data.linkedmdb.org/movie/actor_name> ?actor . } \n",
    "        OPTIONAL { ?movie <http://data.linkedmdb.org/movie/director> ?movie__down_director .  ?movie__down_director <http://data.linkedmdb.org/movie/director_name> ?director . } \n",
    "        \n",
    "        FILTER (?genre = 'Spy' || ?genre = 'Superhero' )\n",
    "        }\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfe27ac0-faf3-419f-85ca-050d79ec0803",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# run the code in a loop and append runtimes and accuracies for every run \n",
    "\n",
    "data_acq_times=[]\n",
    "feature_eng_times=[]\n",
    "vectorization_times=[]\n",
    "vectorAssembler_times=[]\n",
    "total_times=[]\n",
    "train_accuracies= []\n",
    "test_accuracies=[]\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    total_time_start = time.time()\n",
    "    # create an instance of DataAcquisition\n",
    "    # set parameters for null values\n",
    "    dataAcquisitionObject=DataAcquisition(spark)\n",
    "    dataAcquisitionObject.set_amputationMethod('nullReplacement')\n",
    "    dataAcquisitionObject.set_nullReplacementMethod('customValue')\n",
    "    dataAcquisitionObject.set_customValueVariable(-1)\n",
    "    dataAcquisitionObject.set_customStringValueVariable(' ')\n",
    "\n",
    "    # retrieve the data as a Spark DataFrame\n",
    "    start_time1 = time.time()\n",
    "    df = dataAcquisitionObject.getDataFrame(endpoint=endpoint, query=query)\n",
    "    end_time1 = time.time()\n",
    "    data_acq_times.append(round(end_time1 - start_time1, 2))\n",
    "\n",
    "    # create an instance of FeatureEngineering\n",
    "    # call getFeatures function and get features for every column\n",
    "    featureEngineeringObject=FeatureEngineering()\n",
    "    start_time1 = time.time()\n",
    "    df2,features=featureEngineeringObject.getFeatures(df)\n",
    "    end_time1 = time.time()\n",
    "    feature_eng_times.append(round(end_time1 - start_time1, 2))\n",
    "\n",
    "    # apply preprocess to transform genres to have only 1 genre per movie\n",
    "    filtered_df = df2.filter(size(df2.genre) <= 1)\n",
    "    filtered_df = filtered_df.withColumn('genre', concat_ws(',', filtered_df['genre']))\n",
    "    features['genre']['isListOfEntries']=False\n",
    "    features['genre']['featureType']='Single_Categorical_String'\n",
    "\n",
    "    # create an instance of Vectorization module\n",
    "    # call vectorize function and digitaze all the features\n",
    "    vectorizationObject=Vectorization()\n",
    "    start_time1 = time.time()\n",
    "    digitized_df=vectorizationObject.vectorize(filtered_df,features)\n",
    "    end_time1 = time.time()\n",
    "    vectorization_times.append(round(end_time1 - start_time1, 2))\n",
    "\n",
    "    # assemble features into a vector\n",
    "    assembler = VectorAssembler(inputCols=[\"movie_title\", \"director\", \"runtime\", \"actor\"], outputCol=\"features\")\n",
    "    start_time1 = time.time()\n",
    "    assembled_data = assembler.transform(digitized_df)\n",
    "    end_time1 = time.time()\n",
    "    vectorAssembler_times.append(round(end_time1 - start_time1, 2))\n",
    "\n",
    "    # split the data into training and testing sets (70% training, 30% testing)\n",
    "    train_data, test_data = assembled_data.randomSplit([0.7, 0.3])\n",
    "    # create a RandomForestClassifier\n",
    "    rf_classifier = RandomForestClassifier(labelCol=\"genre\", featuresCol=\"features\", numTrees=10)\n",
    "    # train the model\n",
    "    model = rf_classifier.fit(train_data)\n",
    "\n",
    "    # make predictions on both train and test data\n",
    "    train_predictions = model.transform(train_data)\n",
    "    test_predictions = model.transform(test_data)\n",
    "\n",
    "    # evaluate the model on train data using MulticlassClassificationEvaluator\n",
    "    train_evaluator = MulticlassClassificationEvaluator(labelCol=\"genre\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    train_accuracy = train_evaluator.evaluate(train_predictions)\n",
    "\n",
    "    # evaluate the model on test data using MulticlassClassificationEvaluator\n",
    "    test_evaluator = MulticlassClassificationEvaluator(labelCol=\"genre\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    test_accuracy = test_evaluator.evaluate(test_predictions)\n",
    "\n",
    "    # save the accuracies\n",
    "    train_accuracies.append(round(train_accuracy, 5))\n",
    "    test_accuracies.append(round(test_accuracy, 5))\n",
    "\n",
    "    # Print the train and test accuracies\n",
    "    #print(\"Train Accuracy = {:.2f}%\".format(train_accuracy * 100))\n",
    "    #print(\"Test Accuracy = {:.2f}%\".format(test_accuracy * 100))\n",
    "    total_time_end = time.time()\n",
    "    total_times.append(round(total_time_end - total_time_start, 2))    \n",
    "    #print(f\"Total Time: {total_time_end - total_time_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0f6308-41af-42a9-97d2-9564dc4b94c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('data_acq_times:', data_acq_times)\n",
    "print('feature_eng_times:', feature_eng_times)\n",
    "print('vectorization_times:', vectorization_times)\n",
    "print('vectorAssembler_times:', vectorAssembler_times)\n",
    "print('total_times:', total_times)\n",
    "print('train_accuracies:', train_accuracies)\n",
    "print('test_accuracies:', test_accuracies)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "sparkkgml-Classification-runs 2",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
