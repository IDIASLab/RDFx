{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f006fa",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f887fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada97103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrdf2vec import RDF2VecTransformer\n",
    "from pyrdf2vec.embedders import Word2Vec\n",
    "from pyrdf2vec.graphs import KG\n",
    "from pyrdf2vec.walkers import RandomWalker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pseudo-random number generator for reproducibility (commented out here).\n",
    "# RANDOM_STATE = 22\n",
    "\n",
    "# Load the test and training data from TSV files\n",
    "test_data = pd.read_csv(\"../mutag/testSet.tsv\", sep=\"\\t\")\n",
    "train_data = pd.read_csv(\"../mutag/trainingSet.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Extract entities and labels from training and test datasets\n",
    "train_entities = [entity for entity in train_data[\"bond\"]]\n",
    "train_labels = list(train_data[\"label_mutagenic\"])\n",
    "\n",
    "test_entities = [entity for entity in test_data[\"bond\"]]\n",
    "test_labels = list(test_data[\"label_mutagenic\"])\n",
    "\n",
    "# Combine train and test entities and labels\n",
    "entities = train_entities + test_entities\n",
    "labels = train_labels + test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc8d71f-569a-46f2-9ab8-996b18895c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define different vector sizes to evaluate\n",
    "vector_sizes = [100, 200, 300, 400, 500]\n",
    "\n",
    "# Loop through each vector size to train and evaluate embeddings\n",
    "for vector_size in vector_sizes:\n",
    "    # Initialize RDF2VecTransformer with Word2Vec parameters\n",
    "    embeddings = RDF2VecTransformer(\n",
    "        Word2Vec(\n",
    "            vector_size=vector_size,  # The size of the word vectors\n",
    "            window=5,                 # The maximum distance between the current and predicted word\n",
    "            min_count=0,              # Ignores all words with total frequency lower than this\n",
    "            workers=1,                # Number of worker threads to train the model\n",
    "            sg=1,                     # Use skip-gram\n",
    "            hs=1,                     # Use hierarchical softmax\n",
    "            negative=0,               # Number of \"noise words\" to draw\n",
    "            alpha=0.025,              # Initial learning rate\n",
    "            min_alpha=0.0001,         # Minimum learning rate after training\n",
    "            epochs=5,                 # Number of training iterations\n",
    "            seed=42                   # Random seed for reproducibility\n",
    "        ),\n",
    "        walkers=[RandomWalker(max_depth=2)],  # Use RandomWalker with max depth of 2\n",
    "    ).fit_transform(\n",
    "        KG(\n",
    "            \"../mutag/carcinogenesis.owl\",  # Path to the knowledge graph\n",
    "            skip_predicates={\"http://dl-learner.org/carcinogenesis#isMutagenic\"},  # Skip specific predicates\n",
    "        ),\n",
    "        entities\n",
    "    )\n",
    "    \n",
    "    # Split the embeddings into training and test sets\n",
    "    train_embeddings = embeddings[0][:len(train_entities)]\n",
    "    test_embeddings = embeddings[0][len(train_entities):]\n",
    "    \n",
    "    # Perform Grid Search to find the best SVM C-parameter\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), {\"C\": [10**i for i in range(-3, 4)]}, cv=5\n",
    "    )\n",
    "    clf.fit(train_embeddings, train_labels)\n",
    "\n",
    "    # Predict using the best SVM model and evaluate accuracy\n",
    "    predictions = clf.predict(test_embeddings)\n",
    "    print(\n",
    "        f\"Vector Size '{vector_size}' , accuracy : \"\n",
    "        + f\"{accuracy_score(test_labels, predictions) * 100:.4f}%\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark32_p38_cpu_v3]",
   "language": "python",
   "name": "conda-env-pyspark32_p38_cpu_v3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
